{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ec77f7",
   "metadata": {},
   "source": [
    "**This is the resit assignment for recommender system's group project assignment.**\n",
    "\n",
    "**Name & Surname:** Selin YAZICI\n",
    "\n",
    "**Student ID:** i6205952\n",
    "\n",
    "The research question this assignment aims to answer is: 'Are there any differences in the performances of a group recommender using the least misery strategy related to the size of the groups?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4d839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.user_knn import UserUser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ffecf",
   "metadata": {},
   "source": [
    "# The datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51417835",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('preprocessed_dataset/movies.csv')\n",
    "ratings = pd.read_csv('preprocessed_dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b11e58",
   "metadata": {},
   "source": [
    "Because the ratings dataset is too large, I wanted to filter out the outliers. So the total number of items each user rated is obtained and the outliers is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90620ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Items Evaluated by Each User:\n",
      "user\n",
      "1      154\n",
      "2       16\n",
      "3       29\n",
      "4      130\n",
      "5       30\n",
      "      ... \n",
      "606    579\n",
      "607    120\n",
      "608    578\n",
      "609     25\n",
      "610    730\n",
      "Name: item, Length: 610, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_evaluation_counts = ratings.groupby('user')['item'].nunique()\n",
    "print(\"Number of Items Evaluated by Each User:\")\n",
    "print(user_evaluation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e744bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower Bound for Outliers: -109.0\n",
      "Upper Bound for Outliers: 243.0\n",
      "Outliers (user IDs):\n",
      "user\n",
      "18     320\n",
      "19     492\n",
      "21     280\n",
      "28     352\n",
      "42     312\n",
      "      ... \n",
      "600    493\n",
      "603    570\n",
      "606    579\n",
      "608    578\n",
      "610    730\n",
      "Name: item, Length: 67, dtype: int64\n",
      "Filtered DataFrame without Outliers:\n",
      "       user  item  rating  timestamp\n",
      "0         1     1     4.0  964982703\n",
      "1         1     3     4.0  964981247\n",
      "2         1     6     4.0  964982224\n",
      "3         1    70     3.0  964982400\n",
      "4         1   101     5.0  964980868\n",
      "...     ...   ...     ...        ...\n",
      "63703   609   786     3.0  847221025\n",
      "63704   609   833     3.0  847221080\n",
      "63705   609   892     3.0  847221080\n",
      "63706   609  1056     3.0  847221080\n",
      "63707   609  1059     3.0  847221054\n",
      "\n",
      "[32516 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "Q1 = user_evaluation_counts.quantile(0.25)\n",
    "Q3 = user_evaluation_counts.quantile(0.75)\n",
    "\n",
    "# IQR (Interquartile Range)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# upper and lower bounds to identify outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# remove the outliers\n",
    "outliers = (user_evaluation_counts < lower_bound) | (user_evaluation_counts > upper_bound)\n",
    "\n",
    "# filtering the ratings \n",
    "filtered_ratings = ratings[ratings['user'].isin(user_evaluation_counts[~outliers].index)]\n",
    "\n",
    "print(\"Lower Bound for Outliers:\", lower_bound)\n",
    "print(\"Upper Bound for Outliers:\", upper_bound)\n",
    "print(\"Outliers (user IDs):\")\n",
    "print(user_evaluation_counts[outliers])\n",
    "print(\"Filtered DataFrame without Outliers:\")\n",
    "print(filtered_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca74ef68",
   "metadata": {},
   "source": [
    "# Methods We Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec06c9",
   "metadata": {},
   "source": [
    "Generating random groups of size 2,3 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05818e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_groups(df, column_name, group_sizes):\n",
    "    unique_users = df[column_name].unique()\n",
    "\n",
    "    random_groups = {}\n",
    "    \n",
    "    for size in group_sizes:\n",
    "        # Randomly shuffle the unique user IDs\n",
    "        np.random.shuffle(unique_users)\n",
    "\n",
    "        # Calculate the number of groups for the given size\n",
    "        num_groups = len(unique_users) // size\n",
    "\n",
    "        # Generate random groups of the specified size based on the specified column\n",
    "        for i in range(num_groups):\n",
    "            group_users = unique_users[i * size: (i + 1) * size]\n",
    "            group = df[df[column_name].isin(group_users)]\n",
    "            random_groups[i] = group\n",
    "\n",
    "    return random_groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923429b",
   "metadata": {},
   "source": [
    "# Holdout Validation Strategy \n",
    "Holdout Validation Strategy for splitting the dataset such that 80% is used for training and 20% is used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec82335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_method(df, test_size=0.2, random_state=None):\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_set, test_set = train_test_split(filtered_ratings, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ddd9e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "       user   item  rating   timestamp\n",
      "48790   479   2694     3.0  1039362630\n",
      "58596   591    356     4.0   970524486\n",
      "3653     41   2712     5.0  1459368540\n",
      "62996   607    292     4.0   963080256\n",
      "21766   230  50872     3.5  1196305180\n",
      "...     ...    ...     ...         ...\n",
      "55969   562   6870     5.0  1368894017\n",
      "9534     95   1374     4.5  1105400929\n",
      "860      11   1917     4.0   901200037\n",
      "27843   290     24     3.0   975032355\n",
      "42385   425   3408     3.5  1085476542\n",
      "\n",
      "[26012 rows x 4 columns]\n",
      "\n",
      "Testing Set:\n",
      "       user   item  rating   timestamp\n",
      "18426   199   2671     4.0  1021178968\n",
      "821      11    150     5.0   902154266\n",
      "7855     74  30707     4.0  1207502554\n",
      "17764   187   7360     4.5  1161849723\n",
      "37971   385    589     5.0   834691845\n",
      "...     ...    ...     ...         ...\n",
      "75        1   1954     5.0   964982176\n",
      "4         1    101     5.0   964980868\n",
      "13278   137   1136     5.0  1204863777\n",
      "24393   257   2406     3.5  1141625649\n",
      "1108     17   1090     4.5  1322629080\n",
      "\n",
      "[6504 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = holdout_method(filtered_ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the training and testing sets\n",
    "print(\"Training Set:\")\n",
    "print(train_set)\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1effc1",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf619f",
   "metadata": {},
   "source": [
    "For the recommender type, I chose user based collaborative filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a08009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not load LIBBLAS: Could not find module 'libblas' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1217</td>\n",
       "      <td>4.970144</td>\n",
       "      <td>479</td>\n",
       "      <td>assassination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5747</td>\n",
       "      <td>4.745396</td>\n",
       "      <td>479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178</td>\n",
       "      <td>4.733695</td>\n",
       "      <td>479</td>\n",
       "      <td>mommie dearest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27831</td>\n",
       "      <td>4.723562</td>\n",
       "      <td>479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>4.686537</td>\n",
       "      <td>479</td>\n",
       "      <td>mallrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>562</td>\n",
       "      <td>5.589985</td>\n",
       "      <td>189</td>\n",
       "      <td>akira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>785</td>\n",
       "      <td>5.326710</td>\n",
       "      <td>189</td>\n",
       "      <td>wide awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>177593</td>\n",
       "      <td>5.191265</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>56782</td>\n",
       "      <td>5.153706</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>1883</td>\n",
       "      <td>5.052159</td>\n",
       "      <td>189</td>\n",
       "      <td>rio bravo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2710 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item     score  user           title\n",
       "0       1217  4.970144   479   assassination\n",
       "1       5747  4.745396   479             NaN\n",
       "2       1178  4.733695   479  mommie dearest\n",
       "3      27831  4.723562   479             NaN\n",
       "4        101  4.686537   479        mallrats\n",
       "...      ...       ...   ...             ...\n",
       "2705     562  5.589985   189           akira\n",
       "2706     785  5.326710   189      wide awake\n",
       "2707  177593  5.191265   189             NaN\n",
       "2708   56782  5.153706   189             NaN\n",
       "2709    1883  5.052159   189       rio bravo\n",
       "\n",
       "[2710 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_user = UserUser(15, min_nbrs=3)  \n",
    "\n",
    "user_recommendations_list = []\n",
    "\n",
    "for user_id in train_set['user'].unique():\n",
    "    if train_set[train_set['user'] == user_id].empty:\n",
    "        print(f\"User {user_id} has no ratings, and none provided.\")\n",
    "        continue\n",
    "\n",
    "    recsys = Recommender.adapt(user_user)\n",
    "\n",
    "    recsys.fit(train_set)\n",
    "\n",
    "    # Generate recommendations for the current user\n",
    "    user_recommendations = recsys.recommend(user_id, 5)  # Adjust the number of recommendations as needed\n",
    "\n",
    "    # Add the 'user' column to the recommendations DataFrame\n",
    "    user_recommendations['user'] = user_id\n",
    "\n",
    "    # Append the recommendations DataFrame to the list\n",
    "    user_recommendations_list.append(user_recommendations)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "all_user_recommendations_train_set = pd.concat(user_recommendations_list, ignore_index=True)\n",
    "\n",
    "# Join with the 'title' column from 'movies_df'\n",
    "all_user_recommendations_train_set = all_user_recommendations_train_set.join(movies['title'], on='item')\n",
    "\n",
    "# Display the recommendations for all users\n",
    "display(all_user_recommendations_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0797aadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>relevant</th>\n",
       "      <th>predicted_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18426</th>\n",
       "      <td>199</td>\n",
       "      <td>2671</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1021178968</td>\n",
       "      <td>2.535208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>5.0</td>\n",
       "      <td>902154266</td>\n",
       "      <td>4.216202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>74</td>\n",
       "      <td>30707</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1207502554</td>\n",
       "      <td>4.341387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>187</td>\n",
       "      <td>7360</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1161849723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37971</th>\n",
       "      <td>385</td>\n",
       "      <td>589</td>\n",
       "      <td>5.0</td>\n",
       "      <td>834691845</td>\n",
       "      <td>3.523322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>1954</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982176</td>\n",
       "      <td>4.223276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "      <td>3.411987</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13278</th>\n",
       "      <td>137</td>\n",
       "      <td>1136</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1204863777</td>\n",
       "      <td>4.324568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24393</th>\n",
       "      <td>257</td>\n",
       "      <td>2406</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1141625649</td>\n",
       "      <td>3.297843</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>17</td>\n",
       "      <td>1090</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1322629080</td>\n",
       "      <td>4.415957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6504 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user   item  rating   timestamp  predicted_rating  relevant  \\\n",
       "18426   199   2671     4.0  1021178968          2.535208         1   \n",
       "821      11    150     5.0   902154266          4.216202         1   \n",
       "7855     74  30707     4.0  1207502554          4.341387         1   \n",
       "17764   187   7360     4.5  1161849723               NaN         1   \n",
       "37971   385    589     5.0   834691845          3.523322         1   \n",
       "...     ...    ...     ...         ...               ...       ...   \n",
       "75        1   1954     5.0   964982176          4.223276         1   \n",
       "4         1    101     5.0   964980868          3.411987         1   \n",
       "13278   137   1136     5.0  1204863777          4.324568         1   \n",
       "24393   257   2406     3.5  1141625649          3.297843         1   \n",
       "1108     17   1090     4.5  1322629080          4.415957         1   \n",
       "\n",
       "       predicted_relevant  \n",
       "18426                   0  \n",
       "821                     1  \n",
       "7855                    1  \n",
       "17764                   0  \n",
       "37971                   1  \n",
       "...                   ...  \n",
       "75                      1  \n",
       "4                       1  \n",
       "13278                   1  \n",
       "24393                   1  \n",
       "1108                    1  \n",
       "\n",
       "[6504 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted_rating'] = recsys.predict(test_set)\n",
    "test_set['relevant'] = test_set['rating'].apply(lambda x: 1 if x>3 else 0)\n",
    "test_set['predicted_relevant'] = test_set['predicted_rating'].apply(lambda x: 1 if x>3 else 0)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2689bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are creating our random groups and displaying the individual recommendations. \n",
    "\n",
    "group_sizes = [2, 3, 5]\n",
    "random_user_groups3= generate_user_groups(all_user_recommendations_train_set, 'user', group_sizes)\n",
    "\n",
    "# Here we are printing each group and the members, if you want to see it, please uncomment the lines below. \n",
    "\n",
    "# for group_index, group_df in random_user_groups3.items():\n",
    "#     print(f\"Group {group_index} Members:\\n{group_df}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebb5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        item     score  user                 title  Group\n",
      "290     8957  4.435595   262                   NaN      0\n",
      "291      299  4.306298   262               chasers      0\n",
      "292     1204  4.222284   262        eyes wide shut      0\n",
      "293     5747  4.217028   262                   NaN      0\n",
      "294     5673  4.186448   262                   NaN      0\n",
      "...      ...       ...   ...                   ...    ...\n",
      "1575   56782  6.367501   154                   NaN    270\n",
      "1576     175  5.814144   154            virtuosity    270\n",
      "1577  104879  5.796684   154                   NaN    270\n",
      "1578     562  5.793679   154                 akira    270\n",
      "1579    1245  5.748623   154  teaching mrs. tingle    270\n",
      "\n",
      "[4690 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# here we are converting the group dictionary into a dataframe for the sake of easy reading \n",
    "rows = []\n",
    "for group, group_data in random_user_groups3.items():\n",
    "    group_df = group_data.copy()\n",
    "    group_df['Group'] = group\n",
    "    rows.append(group_df)\n",
    "\n",
    "group_dataframe = pd.concat(rows)\n",
    "print(group_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2c131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group\n",
      "0      5\n",
      "1      5\n",
      "2      5\n",
      "3      5\n",
      "4      5\n",
      "      ..\n",
      "266    2\n",
      "267    2\n",
      "268    2\n",
      "269    2\n",
      "270    2\n",
      "Name: user, Length: 271, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_counts = group_dataframe.groupby('Group')['user'].nunique()\n",
    "print(user_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa11daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups with 5 members are: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n",
      "Groups with 3 members are: [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "Groups with 2 members are: [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270]\n"
     ]
    }
   ],
   "source": [
    "# Here, for the sake of readability, we are showing which users belong to which groups. \n",
    "group_info_by_members = {count: [] for count in user_counts.unique()}\n",
    "\n",
    "for group, count in user_counts.items():\n",
    "    group_info_by_members[count].append(group)\n",
    "\n",
    "for count, groups in group_info_by_members.items():\n",
    "    print(f\"Groups with {count} members are: {groups}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76478f6b",
   "metadata": {},
   "source": [
    "# Least Misery Aggregation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b47cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_misery(group_ratings, recommendations_number):\n",
    "    # Aggregate using least misery strategy\n",
    "    aggregated_df = group_ratings.groupby('item').min()\n",
    "    aggregated_df = aggregated_df.sort_values(by=\"score\", ascending=False).reset_index()[['item', 'score']]\n",
    "    \n",
    "    # Recommendation list based on LMS\n",
    "    recommendation_list = list(aggregated_df.head(recommendations_number)['item'])\n",
    "    \n",
    "    # Calculate relevance scores for the recommended items\n",
    "    relevance_scores = group_ratings[group_ratings['item'].isin(recommendation_list)]['score']\n",
    "    \n",
    "    # Calculate relevance using a threshold (e.g., 3)\n",
    "    test_set['relevant'] = test_set['rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "    test_set['predicted_relevant'] = test_set['predicted_rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "    \n",
    "    # Normalize relevance scores\n",
    "    max_score = test_set['rating'].max()  # Assuming ratings are on a scale from 1 to some maximum value\n",
    "    relevance_scores_normalized = relevance_scores / max_score\n",
    "    \n",
    "    return {\"LMS\": {\"recommendations\": recommendation_list, \"relevance_scores\": list(relevance_scores_normalized)}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee8ec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are applying least misery aggregation strategy for 5 recommendations for each group.\n",
    "group_recommendations_dict = {}\n",
    "\n",
    "for group_index, group_df in random_user_groups3.items():\n",
    "    group_recommendations = least_misery(group_df, 5)  \n",
    "    group_recommendations_dict[group_index] = group_recommendations\n",
    "\n",
    "# Here we are desplaying each recommandation and the relevance score for each group. The print statement is too large but if you \n",
    "# want to take a look at it, please uncomment the lines below. \n",
    "\n",
    "# for group_index, recommendations in group_recommendations_dict.items():\n",
    "#     print(f\"Group {group_index} Recommendations:\\n{recommendations}\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983e371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Group Group Name                      Recommendations  \\\n",
      "0        0        LMS     [56715, 136020, 107, 3347, 4036]   \n",
      "1        1        LMS     [97225, 177593, 8958, 319, 4036]   \n",
      "2        2        LMS        [1217, 1178, 2138, 5528, 299]   \n",
      "3        3        LMS     [55276, 299, 1217, 1965, 177593]   \n",
      "4        4        LMS     [55276, 95441, 1952, 2501, 1272]   \n",
      "..     ...        ...                                  ...   \n",
      "266    266        LMS        [6711, 8949, 1204, 5747, 750]   \n",
      "267    267        LMS     [1178, 7169, 8958, 104879, 2135]   \n",
      "268    268        LMS  [97225, 8958, 84944, 32031, 104879]   \n",
      "269    269        LMS         [3424, 4036, 107, 1278, 175]   \n",
      "270    270        LMS     [56782, 104879, 562, 1245, 5617]   \n",
      "\n",
      "                                      Relevance Scores  \n",
      "0    [1.128385951997863, 1.1074719439685003, 1.0784...  \n",
      "1    [1.2042812885921457, 1.160052059107428, 1.1731...  \n",
      "2    [1.1575572082455623, 1.0918556046632508, 1.090...  \n",
      "3    [1.1042490421473554, 1.0921954711293904, 1.107...  \n",
      "4    [1.1359470359848254, 1.1003665005061056, 1.188...  \n",
      "..                                                 ...  \n",
      "266  [0.9908203904268411, 1.0449873428312335, 1.021...  \n",
      "267  [1.0441052042601136, 1.016704154253425, 1.0062...  \n",
      "268  [1.2042812885921457, 1.160052059107428, 1.1581...  \n",
      "269  [1.2077754171515107, 1.1881551175967497, 1.164...  \n",
      "270  [1.0247182485495994, 1.2735002886006634, 1.159...  \n",
      "\n",
      "[271 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# For the sake of readability, we are converting our results to a dataframe. \n",
    "flattened_data = []\n",
    "\n",
    "for group_id, group_data in group_recommendations_dict.items():\n",
    "    group_name = list(group_data.keys())[0]  \n",
    "    recommendations = group_data[group_name]['recommendations']\n",
    "    relevance_scores = group_data[group_name]['relevance_scores']\n",
    "    \n",
    "    row_data = {'Group': group_id, 'Group Name': group_name, 'Recommendations': recommendations, 'Relevance Scores': relevance_scores}\n",
    "    flattened_data.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ae9e0",
   "metadata": {},
   "source": [
    "# nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae1edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Group Group Name      nDCG\n",
      "0        0        LMS  1.000000\n",
      "1        1        LMS  0.999326\n",
      "2        2        LMS  0.992691\n",
      "3        3        LMS  0.998251\n",
      "4        4        LMS  0.986562\n",
      "..     ...        ...       ...\n",
      "266    266        LMS  0.988389\n",
      "267    267        LMS  1.000000\n",
      "268    268        LMS  1.000000\n",
      "269    269        LMS  1.000000\n",
      "270    270        LMS  0.952811\n",
      "\n",
      "[271 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dcg(relevance_scores):\n",
    "    return np.sum((2**relevance_scores - 1) / np.log2(np.arange(2, len(relevance_scores) + 2)))\n",
    "\n",
    "def ndcg(relevance_scores):\n",
    "    ideal_scores = np.sort(relevance_scores)[::-1]\n",
    "    ideal_dcg = dcg(ideal_scores)\n",
    "    if ideal_dcg == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    return dcg(relevance_scores) / ideal_dcg\n",
    "\n",
    "def calculate_ndcg_for_group(df_row):\n",
    "    relevance_scores = df_row['Relevance Scores']\n",
    "\n",
    "    # Normalize relevance scores\n",
    "    max_score = np.max(relevance_scores)  \n",
    "    relevance_scores_normalized = relevance_scores / max_score\n",
    "\n",
    "    # Calculate nDCG for the group\n",
    "    ndcg_value = ndcg(relevance_scores_normalized)\n",
    "\n",
    "    return ndcg_value\n",
    "\n",
    "# Calculate nDCG for each group\n",
    "df['nDCG'] = df.apply(calculate_ndcg_for_group, axis=1)\n",
    "\n",
    "# Display the DataFrame with nDCG values\n",
    "print(df[['Group', 'Group Name', 'nDCG']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2594eeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Group Name</th>\n",
       "      <th>Recommendations</th>\n",
       "      <th>Relevance Scores</th>\n",
       "      <th>nDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[56715, 136020, 107, 3347, 4036]</td>\n",
       "      <td>[1.128385951997863, 1.1074719439685003, 1.0784...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[97225, 177593, 8958, 319, 4036]</td>\n",
       "      <td>[1.2042812885921457, 1.160052059107428, 1.1731...</td>\n",
       "      <td>0.999326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[1217, 1178, 2138, 5528, 299]</td>\n",
       "      <td>[1.1575572082455623, 1.0918556046632508, 1.090...</td>\n",
       "      <td>0.992691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[55276, 299, 1217, 1965, 177593]</td>\n",
       "      <td>[1.1042490421473554, 1.0921954711293904, 1.107...</td>\n",
       "      <td>0.998251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[55276, 95441, 1952, 2501, 1272]</td>\n",
       "      <td>[1.1359470359848254, 1.1003665005061056, 1.188...</td>\n",
       "      <td>0.986562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[6711, 8949, 1204, 5747, 750]</td>\n",
       "      <td>[0.9908203904268411, 1.0449873428312335, 1.021...</td>\n",
       "      <td>0.988389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[1178, 7169, 8958, 104879, 2135]</td>\n",
       "      <td>[1.0441052042601136, 1.016704154253425, 1.0062...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[97225, 8958, 84944, 32031, 104879]</td>\n",
       "      <td>[1.2042812885921457, 1.160052059107428, 1.1581...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[3424, 4036, 107, 1278, 175]</td>\n",
       "      <td>[1.2077754171515107, 1.1881551175967497, 1.164...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>LMS</td>\n",
       "      <td>[56782, 104879, 562, 1245, 5617]</td>\n",
       "      <td>[1.0247182485495994, 1.2735002886006634, 1.159...</td>\n",
       "      <td>0.952811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group Group Name                      Recommendations  \\\n",
       "0        0        LMS     [56715, 136020, 107, 3347, 4036]   \n",
       "1        1        LMS     [97225, 177593, 8958, 319, 4036]   \n",
       "2        2        LMS        [1217, 1178, 2138, 5528, 299]   \n",
       "3        3        LMS     [55276, 299, 1217, 1965, 177593]   \n",
       "4        4        LMS     [55276, 95441, 1952, 2501, 1272]   \n",
       "..     ...        ...                                  ...   \n",
       "266    266        LMS        [6711, 8949, 1204, 5747, 750]   \n",
       "267    267        LMS     [1178, 7169, 8958, 104879, 2135]   \n",
       "268    268        LMS  [97225, 8958, 84944, 32031, 104879]   \n",
       "269    269        LMS         [3424, 4036, 107, 1278, 175]   \n",
       "270    270        LMS     [56782, 104879, 562, 1245, 5617]   \n",
       "\n",
       "                                      Relevance Scores      nDCG  \n",
       "0    [1.128385951997863, 1.1074719439685003, 1.0784...  1.000000  \n",
       "1    [1.2042812885921457, 1.160052059107428, 1.1731...  0.999326  \n",
       "2    [1.1575572082455623, 1.0918556046632508, 1.090...  0.992691  \n",
       "3    [1.1042490421473554, 1.0921954711293904, 1.107...  0.998251  \n",
       "4    [1.1359470359848254, 1.1003665005061056, 1.188...  0.986562  \n",
       "..                                                 ...       ...  \n",
       "266  [0.9908203904268411, 1.0449873428312335, 1.021...  0.988389  \n",
       "267  [1.0441052042601136, 1.016704154253425, 1.0062...  1.000000  \n",
       "268  [1.2042812885921457, 1.160052059107428, 1.1581...  1.000000  \n",
       "269  [1.2077754171515107, 1.1881551175967497, 1.164...  1.000000  \n",
       "270  [1.0247182485495994, 1.2735002886006634, 1.159...  0.952811  \n",
       "\n",
       "[271 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying each nDCG value for each group. \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f3b5e",
   "metadata": {},
   "source": [
    "# Answering the Research Question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9631a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups with 5 members have unique nDCG values: {0.9926906693749296, 1.0, 0.9613955296152898, 0.9805325543872891, 0.9750654532405871, 0.9998755046425494, 0.9987836669091819, 0.9833967385889262, 0.9892809774876883, 0.9949435309884882, 0.9926638572330546, 0.9982873047565802, 0.9979595394220481, 0.9971478749612397, 0.9914019498611671, 0.9777074544637298, 0.9831599037042803, 0.9873156034177702, 0.9867163977059553, 0.9884089277789491, 0.9979895552678613, 0.9853649745184299, 0.9921164538055123, 0.9926471723956823, 0.9996044559689219, 0.9996567877303244, 0.9798743659044371, 0.9934398271709429, 0.9957976573458512, 0.9653200435838382, 0.9984942423399029, 0.976431737892021, 0.9974096512895027, 0.9867867400480119, 0.9934556261179186, 0.9998022086103594, 0.9339761537599619, 0.9749378375790213, 0.9692987636839531, 0.9958468855825068, 0.9991892265309283, 0.9809136826791922, 0.9993259250286338, 0.9990122002769191, 0.9929513681678142, 0.9663289079027049, 0.9777976910322775, 0.9952349904772381, 0.9859112187415332, 0.9908450720232963, 0.994412084399395, 0.9615366574012918, 0.9603515110469929, 0.9918872936738254, 0.9785289907061265, 0.9858803329669168, 0.9852272597652021, 0.9998766743447928, 0.9926513709214886, 0.9940917247425132, 0.9827586780335088, 0.9747401275154736, 0.9964149976913347, 0.9985071287075826, 0.9999276211149593, 0.9967026636757688, 0.9884258703775254, 0.996444493520435, 0.9913787824567984, 0.9865623490116698, 0.9868825355289345, 0.9821516088787904, 0.9698075260086081, 0.9956871393438358, 0.9989804608550013, 0.9983117380003034, 0.9982512199683701, 0.9793007881374113, 0.9926817612895567, 0.9982037221982158, 0.9648622898038147}\n",
      "Groups with 3 members have unique nDCG values: {0.9995763073730428, 1.0, 0.9997171653955738, 0.9975012136235643, 0.9987200511620075, 0.9998293650270303, 0.9899320181697095, 0.9919860266157743, 0.9933461254882362, 0.966456926485794, 0.9733244959106565, 0.9744856644306205, 0.9933733747806281, 0.9933883328270989, 0.9910895670653308, 0.9985056370548127, 0.9992456664137722, 0.9876723261493034, 0.9983823068369434, 0.9921570321870898, 0.9910936904962468, 0.9695722655462181, 0.9993093784074033, 0.9702103036715934, 0.9984576940892778, 0.983346690276961, 0.9910708012838549, 0.991950246422099, 0.9907174690985975, 0.9847411932456939, 0.9886433321675014, 0.9920806073636552, 0.9969729096311248, 0.9939468494507626, 0.9634317145306243, 0.96816087111458, 0.9988761902692372, 0.9981193375421954, 0.9999895065822558, 0.9946425017993561, 0.9739880771311351, 0.9720484667194067, 0.9648714069435279, 0.9901951417194873, 0.9974194123239709, 0.9772971912452647, 0.9835327422685403, 0.9991306119784527, 0.9123199357640972, 0.9983645644312665}\n",
      "Groups with 2 members have unique nDCG values: {0.9796608855902368, 1.0, 0.9947077887883712, 0.9813041930172273, 0.9906567907706402, 0.9991108544074737, 0.9996128323941874, 0.9562773648189128, 0.9827709708941591, 0.9996466391715835, 0.9888739724117226, 0.953107793839248, 0.9870586810397735, 0.9528114225611602, 0.9989768556101897, 0.9889367659078929, 0.9457237394451643, 0.9933956838817033, 0.9883886385551954, 0.9977055892131107, 0.9932443111649405, 0.9902138033659937, 0.9335103851972402, 0.9469355975235105, 0.9998184703941044, 0.9998538098137103, 0.9960927310437999, 0.9388458958918087, 0.989435756486958, 0.9197769901533585, 0.9941607019110417, 0.9743788432252383, 0.9907715941879329, 0.992288491598689}\n"
     ]
    }
   ],
   "source": [
    "df_merged = df.merge(group_dataframe, on='Group')\n",
    "ndcg_by_members = {count: set() for count in user_counts.unique()}\n",
    "\n",
    "for count, groups in group_info_by_members.items():\n",
    "    ndcg_values = set(df_merged[df_merged['Group'].isin(groups)]['nDCG'])\n",
    "    ndcg_by_members[count].update(ndcg_values)\n",
    "\n",
    "for count, ndcg_values in ndcg_by_members.items():\n",
    "    print(f\"Groups with {count} members have unique nDCG values: {ndcg_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15231db6",
   "metadata": {},
   "source": [
    "- Looking at the nDCG values for groups with sizes 2,3 and 5, the analysis suggests that group size may influence the performance of the least misery strategy in group recommendation systems.\n",
    "\n",
    "- Larger groups may benefit from a broader range of preferences, leading to both higher and lower nDCG values.\n",
    "\n",
    "- Smaller groups may face challenges in achieving consensus, resulting in more varied nDCG scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
